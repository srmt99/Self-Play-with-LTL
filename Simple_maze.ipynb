{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IuVxe65AoY_M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! wget http://www.lrde.epita.fr/dload/spot/spot-2.10.6.tar.gz\n",
        "# ! tar -xf spot-2.10.6.tar.gz\n",
        "# %cd spot-2.10.6\n",
        "# ! ./configure --prefix ~/usr\n",
        "# ! make\n",
        "# ! make install"
      ],
      "metadata": {
        "id": "O1ozzPW1aeHj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import spot\n",
        "# print(spot.formula('[]<>p0 || <>[]p1'))"
      ],
      "metadata": {
        "id": "ikIQsyfmam5U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/fpom/pytl.git\n",
        "%cd pytl\n",
        "! python3 setup.py install\n",
        "import tl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnWMkw3Gn2UW",
        "outputId": "5a0ff1dd-e47c-405f-e7fb-c1bfcd9ddbd5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytl'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 207 (delta 109), reused 125 (delta 41), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (207/207), 76.43 KiB | 1.25 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "/content/pytl\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating pytl.egg-info\n",
            "writing pytl.egg-info/PKG-INFO\n",
            "writing dependency_links to pytl.egg-info/dependency_links.txt\n",
            "writing requirements to pytl.egg-info/requires.txt\n",
            "writing top-level names to pytl.egg-info/top_level.txt\n",
            "writing manifest file 'pytl.egg-info/SOURCES.txt'\n",
            "adding license file 'COPYING.md'\n",
            "writing manifest file 'pytl.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/tl\n",
            "copying tl/tlparse.py -> build/lib/tl\n",
            "copying tl/__init__.py -> build/lib/tl\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/tl\n",
            "copying build/lib/tl/tlparse.py -> build/bdist.linux-x86_64/egg/tl\n",
            "copying build/lib/tl/__init__.py -> build/bdist.linux-x86_64/egg/tl\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tl/tlparse.py to tlparse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tl/__init__.py to __init__.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytl.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytl.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytl.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytl.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytl.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/pytl-0.2-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pytl-0.2-py3.7.egg\n",
            "Copying pytl-0.2-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pytl 0.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pytl-0.2-py3.7.egg\n",
            "Processing dependencies for pytl==0.2\n",
            "Searching for TatSu\n",
            "Reading https://pypi.org/simple/TatSu/\n",
            "Downloading https://files.pythonhosted.org/packages/78/67/413a03b1048f9f237e3f242e6e829688d8c9cf1fbe6bd8bb5f574ae67ac9/TatSu-5.8.3-py2.py3-none-any.whl#sha256=0a836692e67247cad9f251e083b045b13345cc715e69a7fbc16522beaa0f2163\n",
            "Best match: TatSu 5.8.3\n",
            "Processing TatSu-5.8.3-py2.py3-none-any.whl\n",
            "Installing TatSu-5.8.3-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding TatSu 5.8.3 to easy-install.pth file\n",
            "Installing g2e script to /usr/local/bin\n",
            "Installing tatsu script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/TatSu-5.8.3-py3.7.egg\n",
            "Finished processing dependencies for pytl==0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# G   (always)\n",
        "# F   (eventually)\n",
        "# U   (until)\n",
        "# X   (next)\n",
        "# &   (and)\n",
        "# |   (or)\n",
        "# ~   (negate)\n",
        "\n",
        "# []x & <> ([]b & []d)\n",
        "\n",
        "tl.parse(\"G(x)&F(Gb&Gd)\").its_ltl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ueYbImDXuYXx",
        "outputId": "978ab6ec-5aad-43dd-a259-4c3996ee2573"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(G\"x=1\")&&(F(\"Gb=1\")&&(\"Gd=1\"))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Grid_world:\n",
        "  def __init__(self, map_num=None, shape=None, n_obstacles=None, n_goals=None, like=None, ordered=False):\n",
        "    \n",
        "    self.shape = shape\n",
        "    self.map_num = map_num\n",
        "    self.map = None\n",
        "    self.ordered = ordered\n",
        "    self.n_goals = n_goals\n",
        "    self.n_obstacles = n_obstacles\n",
        "    \n",
        "    if like != None:\n",
        "      self.shape = like.shape\n",
        "      self.map = like.map.copy()\n",
        "      self.n_goals = like.n_goals\n",
        "      self.n_obstacles = like.n_obstacles\n",
        "      self.ordered = like.ordered\n",
        "\n",
        "    elif map_num != None:\n",
        "      self.map = self.set_grid_world(map_num)\n",
        "      self.shape = self.map.shape\n",
        "    elif shape != None:\n",
        "      self.generate_grid_world(self.shape, n_obstacles, n_goals)\n",
        "    else:\n",
        "      print(\"map_num & shape can't be 'None' at the same time.\")\n",
        "\n",
        "  def set_grid_world(self, map):\n",
        "        if map == 0:\n",
        "          grid_world = np.zeros((5,5))\n",
        "\n",
        "          grid_world[0,4] = 2 # destination\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "        elif map == 1:\n",
        "\n",
        "          grid_world = np.zeros((5,5))\n",
        "          grid_world[[2,3],3] = -1 # holes\n",
        "          grid_world[[0,1],1] = -1 # holes\n",
        "\n",
        "          grid_world[0, 4] = 2 # destination\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "        elif map == 2:\n",
        "\n",
        "          grid_world = np.zeros((5,5))\n",
        "          grid_world[[0,2,3],3] = -1 # holes\n",
        "          grid_world[[0,1,2,4],1] = -1 # holes\n",
        "\n",
        "          grid_world[0, 4] = 2 # destination\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "        elif map == 3:\n",
        "\n",
        "          grid_world = np.zeros((10,10))\n",
        "          grid_world[[0,6,7,9],1] = -1 # holes\n",
        "          grid_world[[0,1,2,3,8],3] = -1 # holes\n",
        "          grid_world[[0,1,2,3,4,5],5] = -1 # holes\n",
        "\n",
        "          grid_world[-1, -1] = 2 # destination\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "        elif map == 4:\n",
        "\n",
        "          grid_world = np.zeros((10,10))\n",
        "          grid_world[[0,1,2,4,6,7,9],1] = -1 # holes\n",
        "          grid_world[[0,2,3, 6,7,8],3] = -1 # holes\n",
        "          grid_world[[1,2,3,4,5,6],5] = -1 # holes\n",
        "          grid_world[[2,3,5,6,7,9],7] = -1 # holes\n",
        "\n",
        "          grid_world[-1, -1] = 2 # destination\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "        \n",
        "        elif map == 5:\n",
        "\n",
        "          grid_world = np.zeros((16,16))\n",
        "          grid_world[[0,1,2,4,6,7,9],1] = -1 # holes\n",
        "          grid_world[[0,2,3, 6,7,8],3] = -1 # holes\n",
        "          grid_world[[1,2,3,4,5,6],5] = -1 # holes\n",
        "          grid_world[[2,3,5,6,7,9],7] = -1 # holes\n",
        "          grid_world[[4,5,6,7,8,9,10,11,12,13,14,15],9] = -1 # holes\n",
        "          grid_world[[1,2,3,4,5,6,7,8, 12, 14],11] = -1 # holes\n",
        "          grid_world[[7,9,10,11,12,13,15],13] = -1 # holes\n",
        "\n",
        "          grid_world[-2, -3] = 2 # destination\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "        elif map == 10:\n",
        "\n",
        "          grid_world = np.zeros((3,3))\n",
        "          grid_world[1,[0,1]] = -1 # holes\n",
        "\n",
        "          grid_world[-1, 0] = 2 # destination\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "        elif map == 20:\n",
        "\n",
        "          grid_world = np.zeros((8,8))\n",
        "\n",
        "          grid_world[[0,-1], -1] = 2 # destinations\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "        elif map == 21:\n",
        "\n",
        "          grid_world = np.zeros((5,5))\n",
        "\n",
        "          grid_world[[0,-1], -1] = 2 # destinations\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "          grid_world[[0,2,3],3] = -1 # holes\n",
        "          grid_world[[0,1,2,4],1] = -1 # holes\n",
        "        \n",
        "        elif map == 22:\n",
        "\n",
        "          grid_world = np.zeros((5,5))\n",
        "\n",
        "          grid_world[[0,-1], -1] = 2 # destinations\n",
        "          grid_world[[0,-1], -3] = 2 # destinations\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "\n",
        "          grid_world[[0,2,3],3] = -1 # holes\n",
        "          grid_world[[0,1,2,4],1] = -1 # holes\n",
        "\n",
        "        elif map == 24:\n",
        "\n",
        "          grid_world = np.zeros((10,10))\n",
        "\n",
        "          grid_world[[0,-1], -1] = 2 # destinations\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "          \n",
        "          grid_world[[0,6,7,9],1] = -1 # holes\n",
        "          grid_world[[0,1,2,3,8],3] = -1 # holes\n",
        "          grid_world[[0,1,2,3,4,5],5] = -1 # holes\n",
        "\n",
        "        elif map == 25:\n",
        "\n",
        "          grid_world = np.zeros((16,16))\n",
        "\n",
        "          grid_world[[0,-1], -1] = 2 # destinations\n",
        "          grid_world[[2,-3], -4] = 2 # destinations\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "          \n",
        "          grid_world[[0,6,7,9],1] = -1 # holes\n",
        "          grid_world[[0,1,2,3,8],3] = -1 # holes\n",
        "          grid_world[[0,1,2,3,4,5],5] = -1 # holes\n",
        "\n",
        "        elif map == 30:\n",
        "\n",
        "          grid_world = np.zeros((10,10))\n",
        "\n",
        "          grid_world[0, -1] = 2 # destinations\n",
        "          grid_world[1, -2] = 3 # destinations\n",
        "          grid_world[2, -3] = 4 # destinations\n",
        "          grid_world[0,0] = 1 # starting point\n",
        "          \n",
        "          grid_world[[0,6,7,9],1] = -1 # holes\n",
        "          grid_world[[0,1,2,3,8],3] = -1 # holes\n",
        "          grid_world[[0,1,2,3,4,5],5] = -1 # holes\n",
        "\n",
        "        return grid_world.astype(int)\n",
        "\n",
        "  def get_locations(self, target, absolute_loc=True, as_list=False):\n",
        "\n",
        "      if target==None: i, j = np.where(self.map==2)\n",
        "      elif type(target)==int: i, j = np.where(self.map==target)\n",
        "      else:\n",
        "        i, j = [], []\n",
        "        for t in target:\n",
        "          x,y = np.where(self.map==t)\n",
        "          try:\n",
        "              i.append(x[0])\n",
        "              j.append(y[0])\n",
        "          except:\n",
        "            pass # the goal was overwritten by the agent, ignore it\n",
        "\n",
        "      if absolute_loc:\n",
        "        if len(i)>1 or as_list: return [(i[k]*len(self.map) + j[k]) for k in range(len(i))]\n",
        "        else: return i[0]*len(self.map) + j[0]\n",
        "\n",
        "      else:\n",
        "        if len(i)>1 or as_list: return [(i[k], j[k], i[k]*len(self.map) + j[k]) for k in range(len(i))]\n",
        "        else: return i[0], j[0], i[0]*len(self.map) + j[0]\n",
        "\n",
        "  def get_surroundings(self, location_i, location_j):\n",
        "\n",
        "      surroundings = -np.ones(4)\n",
        "      if location_j < len(self.map)-1:\n",
        "          surroundings[0] = self.map[location_i][location_j+1]\n",
        "      if location_i > 0:\n",
        "          surroundings[1] = self.map[location_i-1][location_j]\n",
        "      if location_j > 0:\n",
        "          surroundings[2] = self.map[location_i][location_j-1]\n",
        "      if location_i < len(self.map)-1:\n",
        "          surroundings[3] = self.map[location_i+1][location_j]\n",
        "      return surroundings\n",
        "\n",
        "  def add_item(self, n_items, item):\n",
        "\n",
        "      x,y = self.shape\n",
        "      for _ in range(n_items):\n",
        "        i,j = np.random.randint(x), np.random.randint(y)\n",
        "        while(self.map[i,j]!=0):\n",
        "          i,j = np.random.randint(x), np.random.randint(y)\n",
        "        self.map[i,j] = item\n",
        "        if self.ordered: item += 1\n",
        "\n",
        "  def add_obstacles(self, n_obstacles=None):\n",
        "\n",
        "      x,y = self.shape\n",
        "\n",
        "      obstacles_in_row = x//2\n",
        "\n",
        "      k = 0\n",
        "      for j in range(1,y,2):\n",
        "        for k in range(obstacles_in_row):\n",
        "          i = np.random.randint(x)\n",
        "          if self.map[i,j]==0:\n",
        "            self.map[i,j] = -1\n",
        "        \n",
        "  def generate_grid_world(self, shape, n_obstacles, n_goals):\n",
        "\n",
        "    self.map = np.zeros(shape)\n",
        "    self.map[0,0] = 1 # starting point\n",
        "\n",
        "    self.add_item(n_goals, 2) # adding goals\n",
        "\n",
        "    self.add_obstacles(n_obstacles)\n",
        "\n",
        "  def get_goal_tragectory(self, offset=2):\n",
        "    if self.ordered: return [i+offset for i in range(self.n_goals)]\n",
        "    # else: return [offset for i in range(self.n_goals)]\n",
        "    else: return None\n",
        "  \n",
        "  def copy(self):\n",
        "    return Grid_world(like=self)"
      ],
      "metadata": {
        "id": "8SSft-fJog6y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v3VScjuN9Hu7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_world = Grid_world(shape=(4,4), n_goals=4, ordered=True)\n",
        "grid_world.get_locations(None, as_list=False),grid_world.map, grid_world.get_goal_tragectory()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7-Ccm45oimr",
        "outputId": "7f6350cd-1e4e-4e06-e331-f97651470420"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, array([[ 1.,  0.,  0.,  4.],\n",
              "        [ 0.,  0.,  5., -1.],\n",
              "        [ 0., -1.,  3.,  2.],\n",
              "        [ 0.,  0.,  0., -1.]]), [2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Concatenate, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "def build_model(grid_world_shape):\n",
        "  inputs = Input(shape=grid_world_shape)\n",
        "\n",
        "  inputs = Flatten()(inputs)\n",
        "  x = Dense(32, activation='relu')(inputs)\n",
        "  x = Dense(16, activation='relu')(x)\n",
        "  move_predictions = Dense(5, activation='softmax')(x)\n",
        "  rew_predictions = Dense(1, activation='tanh')(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=(move_predictions, rew_predictions))\n",
        "  # model = Model(inputs=inputs, outputs=move_predictions)\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=['categorical_crossentropy', 'mse'],\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = build_model(grid_world.shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyMZk6xeoira",
        "outputId": "eb51457f-6420-47d5-e095-6e806abd1ee7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           544         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 16)           528         ['dense[1][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 5)            85          ['dense_1[1][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            17          ['dense_1[1][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,174\n",
            "Trainable params: 1,174\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_move(grid_world, loc_i, loc_j, move):\n",
        "    \n",
        "    new_loc_i, new_loc_j = loc_i, loc_j\n",
        "    \n",
        "    if move==4:\n",
        "        pass\n",
        "    elif move==0 and loc_j< len(grid_world.map[0])-1:\n",
        "        new_loc_j += 1\n",
        "    elif move==1 and loc_i > 0:\n",
        "        new_loc_i -= 1\n",
        "    elif move==2 and loc_j > 0:\n",
        "        new_loc_j -= 1\n",
        "    elif move==3 and loc_i < len(grid_world.map)-1:\n",
        "        new_loc_i += 1\n",
        "\n",
        "    new_grid_world = Grid_world(like=grid_world)\n",
        "    # apply the change in the real world\n",
        "    new_grid_world.map[loc_i][loc_j] = 0\n",
        "    new_grid_world.map[new_loc_i][new_loc_j] = 1\n",
        "\n",
        "    return new_grid_world, new_loc_i, new_loc_j\n",
        "\n",
        "# def tree_search(grid_world, max_depth=3):\n",
        "\n",
        "#   # tree = [(0, 0), (1, 0), (2, 0), (3, 0)]\n",
        "\n",
        "#   location_i, location_j, location = get_location(grid_world)\n",
        "#   surroundings = get_surroundings(grid_world, location_i, location_j)\n",
        "#   curr_node = 0.25*np.ones(4)\n",
        "\n",
        "#   if max_depth<1:\n",
        "#     return curr_node\n",
        "\n",
        "#   for i in range(4):\n",
        "#     if surroundings[i] == -1:\n",
        "#       curr_node[i] = 0\n",
        "#     elif surroundings[i] == 2:\n",
        "#       curr_node[i] = 1\n",
        "#     else:\n",
        "#         new_location_i, new_location_j = make_move(grid_world, location_i, location_j, i)\n",
        "#         grid_world[location_i][location_j] = 0\n",
        "#         grid_world[new_location_i][new_location_j] = 1\n",
        "#         curr_node[i] = tree_search(grid_world.copy(), max_depth=max_depth-1).mean()\n",
        "  \n",
        "#   return np.exp(curr_node) / np.sum(np.exp(curr_node))"
      ],
      "metadata": {
        "id": "0d_RAn0FoiuL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hash_state(state):\n",
        "  hash = ''\n",
        "  for i in state.flatten():\n",
        "    hash += str(i)\n",
        "  return hash\n",
        "\n",
        "def check_specifications(tragectory, goal_locations, obstacle_locations, goal_tragectory=None, stay_at_goal=False):\n",
        "\n",
        "  # check obstacles\n",
        "  if any([i in obstacle_locations for i in tragectory]): return -1\n",
        "\n",
        "  # check goals visited\n",
        "  if all([i in tragectory for i in goal_locations]):\n",
        "\n",
        "    if goal_tragectory != None: # order of visiting goal states\n",
        "        for i in range(len(goal_locations)-1):\n",
        "            if tragectory.index(goal_locations[i]) > tragectory.index(goal_locations[i+1]):\n",
        "                return -1\n",
        "        return 1\n",
        "    elif stay_at_goal: # have to always stay at last goal position\n",
        "        last_idx = tragectory.index(goal_locations[-1])\n",
        "        for i in tragectory[last_idx:]:\n",
        "          if i != goal_locations[-1]:\n",
        "            return -1\n",
        "        return 1\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "  return 0\n"
      ],
      "metadata": {
        "id": "D8TT-Xm4bzoR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostly finds the way to the goal, but not necesserily the optimal way\n",
        "# n_samples, 'C' and 'tow' need tuning\n",
        "# relies mostly on MCTS. NN not tuned\n",
        "\n",
        "# our problem is an infinite horizon VS go (finite horizon): search depth limit\n",
        "# * we can get to the same position, but not in Go -> solution: Discount factor??\n",
        "\n",
        "\n",
        "# higher order MDP"
      ],
      "metadata": {
        "id": "dQJY7LuCA_9F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a_t = argmax(Q(s_t,a) +  U(s-t,a))\n",
        "\n",
        "# NODE:\n",
        "# N(s,a): visit count \n",
        "# W(s,a): total action-value\n",
        "# Q(s,a): mean action-value\n",
        "# P(s,a): prior probability\n",
        "# U(s,a) = C * P(s,a) * (np.sqrt(np.sum(N(s,:))))/(1+N(s,a))\n",
        "\n",
        "# leaf nodes:\n",
        "# N(s_l, a) = 0\n",
        "# W(s_l, a) = 0\n",
        "# Q(s_l, a) = 0\n",
        "# P(s_l, a) = P_a\n",
        "\n",
        "# backward pass\n",
        "# N(s,a) += 1\n",
        "# W(s,a) += v\n",
        "# Q(s,a) = W(s,a)/N(s,a)\n",
        "\n",
        "# Pi(a|s_0) = N(s_0, a)**(1/tow) / np.sum(N(s_0,:)**(1/tow))\n",
        "\n",
        "mc_calls = 0\n",
        "\n",
        "def MCTS_rec(model, root, tree, obstacle_locations, goal_locations, tragectory, goal_tragectory=None, N={}, W={}, Q={}, P={}, C=1, depth=100):\n",
        "\n",
        "  # tree structure: a dict from 'state_hash' -> (grid_world, children)\n",
        "\n",
        "  global mc_calls # for time analysis purposes only\n",
        "  mc_calls += 1 # counting number of calls to this function\n",
        "\n",
        " \n",
        "  grid_world = tree[root][0] # get the raw grid_world state\n",
        "\n",
        "  location_i, location_j, location = grid_world.get_locations(target=1, absolute_loc=False) # get current location of the agent\n",
        "  tragectory.append(location)\n",
        "\n",
        "  # check if the game is terminated\n",
        "  outcome = check_specifications(tragectory, goal_locations, obstacle_locations, goal_tragectory)\n",
        "  if outcome == 1: # game won\n",
        "      return 1\n",
        "  elif outcome == -1:\n",
        "      return -1\n",
        "\n",
        "  if depth < 0: # search depth limit reached\n",
        "      return -1\n",
        "\n",
        "  elif root not in N: # unexplored leaf node\n",
        "      model_output = model(grid_world.map.reshape(1, -1))\n",
        "      value = model_output[1].numpy()[0][0]\n",
        "      P[root] = model_output[0].numpy()[0]\n",
        "      N[root] = np.zeros(5)\n",
        "      W[root] = np.zeros(5)\n",
        "      Q[root] = np.zeros(5)\n",
        "      return value\n",
        "\n",
        "  ### selecting the next node to expand ###\n",
        "  U = C * P[root] * (np.sqrt(np.sum(N[root])))/(1+N[root])\n",
        "  next_move = (U + Q[root]).argmax()\n",
        "  # print(U, Q[root])\n",
        "  # next_move = np.random.randint(4)\n",
        "  #########################################\n",
        "  \n",
        "  ### creating the next subtree ###\n",
        "  next_grid_world, new_location_i, new_location_j = make_move(grid_world, location_i, location_j, next_move)\n",
        "  sub_root = hash_state(next_grid_world.map)\n",
        "  sub_tree = {sub_root :(next_grid_world, {})}\n",
        "  #################################\n",
        "  ### expanding the next move and back tracking ###\n",
        "  value = MCTS_rec(model, sub_root, sub_tree, obstacle_locations, goal_locations, tragectory, goal_tragectory,  N, W, Q, P, C=C, depth=depth-1)\n",
        "  N[root][next_move] += 1\n",
        "  W[root][next_move] += value\n",
        "  # if root == '1-10-120-10000-10-10000-100-1000' and next_move==3:\n",
        "    # print(\"value:\", value)\n",
        "    # print('U:',U,'Q:', Q[root])\n",
        "  Q[root][next_move] = W[root][next_move]/N[root][next_move]\n",
        "  #################################################\n",
        "  return value\n",
        "\n",
        "\n",
        "\n",
        "def MCTS(model, root, tree, goal_locations, obstacle_locations, N, W, Q, P, n_samples=100, tow=1, C=1, depth=100):\n",
        "\n",
        "  grid_world = tree[root][0] # get the grid_world\n",
        "  goal_tragectory = grid_world.get_goal_tragectory()\n",
        "\n",
        "  for sample in range(n_samples):\n",
        "    MCTS_rec(model, root, tree.copy(), obstacle_locations, goal_locations, [], goal_tragectory,  N, W, Q, P, C=C, depth=depth)\n",
        "\n",
        "  Pi = (N[root]**(1/tow)) / np.sum(N[root]**(1/tow))\n",
        "  return Pi\n",
        "\n",
        "grid_world = Grid_world(map_num=2)\n",
        "goal_tragectory = grid_world.get_goal_tragectory()\n",
        "goal_locations = grid_world.get_locations(goal_tragectory, as_list=True)\n",
        "obstacle_locations = grid_world.get_locations(-1, as_list=True)\n",
        "model = build_model(grid_world.shape)\n",
        "\n",
        "t1 = time.time()\n",
        "N, W, Q, P = {}, {}, {}, {}\n",
        "# P[hash_state(grid_world)] = model(grid_world.reshape(1, -1))[0].numpy()[0]\n",
        "Pi = MCTS(model, hash_state(grid_world.map), {hash_state(grid_world.map):(grid_world, {})},goal_locations, obstacle_locations, N, W, Q, P, n_samples=500, tow=0.1, C=5)\n",
        "t2 = time.time()\n",
        "print('MCTS runtime',t2 - t1, 'sec', \"(\",(t2-t1)/mc_calls,\"/\",mc_calls,\")\" )\n",
        "print(\"Policy:\", Pi)\n",
        "print(grid_world.map)\n",
        "\n",
        "for i in N:\n",
        "  print(i, N[i], Q[i])"
      ],
      "metadata": {
        "id": "7F9gjXjezN11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235cd876-5cca-4a9b-a4cd-46e539fe4385"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCTS runtime 0.3712003231048584 sec ( 0.00015383353630537023 / 2413 )\n",
            "Policy: [8.87802095e-01 1.87548605e-03 1.08149976e-01 2.96956585e-04\n",
            " 1.87548605e-03]\n",
            "[[ 1 -1  0 -1  2]\n",
            " [ 0 -1  0  0  0]\n",
            " [ 0 -1  0 -1  0]\n",
            " [ 0  0  0 -1  0]\n",
            " [ 0 -1  0  0  0]]\n",
            "1-10-120-10000-10-10000-100-1000 [374. 202. 303. 168. 202.] [-1.         -1.         -1.         -0.97948957 -1.        ]\n",
            "0-10-121-10000-10-10000-100-1000 [107.  50. 100.  56. 100.] [-1.         -1.         -1.         -0.95811345 -1.        ]\n",
            "0-10-120-10001-10-10000-100-1000 [ 2. 50. 99.  1. 99.] [-1.         -1.         -1.          0.23362777 -1.        ]\n",
            "0-10-120-10000-10-10100-100-1000 [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_world.map)\n",
        "ng, new_loc_i, new_loc_j = make_move(grid_world, 0, 0, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WKwc01yinvp",
        "outputId": "1cc8f344-e7d4-43a5-ce1b-031e4d6ce834"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 -1  0 -1  2]\n",
            " [ 0 -1  0  0  0]\n",
            " [ 0 -1  0 -1  0]\n",
            " [ 0  0  0 -1  0]\n",
            " [ 0 -1  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_world.map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOa8KWe5td-L",
        "outputId": "63a8522e-1aad-4c8b-a673-25ec842d37ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1, -1,  0, -1,  2],\n",
              "       [ 0, -1,  0,  0,  0],\n",
              "       [ 0, -1,  0, -1,  0],\n",
              "       [ 0,  0,  0, -1,  0],\n",
              "       [ 0, -1,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in N:\n",
        "  print(i, N[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owE1BnRZbUMN",
        "outputId": "df0dc256-0fcc-49e8-d9bc-76ee09ab6ec0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-10-120-10000-10-10000-100-1000 [374. 202. 303. 168. 202.]\n",
            "0-10-121-10000-10-10000-100-1000 [107.  50. 100.  56. 100.]\n",
            "0-10-120-10001-10-10000-100-1000 [ 2. 50. 99.  1. 99.]\n",
            "0-10-120-10000-10-10100-100-1000 [0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Problems of MCTS:\n",
        "# seems to have a bias towards stying in the same position\n",
        "# requires many samples, not good with few samples\n",
        "# time consuming: should inspect carefully and implement more efficiently"
      ],
      "metadata": {
        "id": "avD5kjAGYrmF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Effect of C\n",
        "# C = 0 -> Policy: [0.45253401 0.07407522 0.         0.         0.47339077]\n",
        "# C = 0.1 -> Policy: [0.45253401 0.07407522 0.         0.         0.47339077]\n",
        "# C = 1 -> [0.45253401 0.07407522 0.         0.         0.47339077]\n",
        "# C = 10 -> [0.45253401 0.07407522 0.         0.         0.47339077]\n",
        "# C = 100 -> [0.45253401 0.07407522 0.         0.         0.47339077]"
      ],
      "metadata": {
        "id": "BWtM7Wz2D6jD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(grid_world, model, n_steps=150, C=3, tow=1, n_samples=300, N={}, W={}, Q={}, P={}, verbose=0):\n",
        "    state_history = []\n",
        "    action_history = []\n",
        "    better_policy = []\n",
        "    tragectory = []\n",
        "    reward = 0\n",
        "    goal_tragectory = grid_world.get_goal_tragectory()\n",
        "    goal_locations = grid_world.get_locations(goal_tragectory, as_list=True)\n",
        "    obstacle_locations = grid_world.get_locations(-1, as_list=True)\n",
        "\n",
        "    for step in range(n_steps):\n",
        "        \n",
        "        location_i, location_j, location = grid_world.get_locations(1, False)\n",
        "        tragectory.append(location)\n",
        "\n",
        "        outcome = check_specifications(tragectory, goal_locations, obstacle_locations, goal_tragectory)\n",
        "        if outcome == 1: # game won\n",
        "            reward = 1\n",
        "            break\n",
        "        elif outcome == -1: # game lost\n",
        "            reward = 0\n",
        "            break\n",
        "\n",
        "        state_history.append(grid_world.map.copy())\n",
        "            \n",
        "        # MCTS - policy improvment\n",
        "        Pi = MCTS(model, hash_state(grid_world.map), {hash_state(grid_world.map):(grid_world, {})}, goal_locations, obstacle_locations, N, W, Q, P, n_samples=n_samples, tow=tow, C=C, depth=n_steps+1)\n",
        "        better_policy.append(Pi.copy())\n",
        "          \n",
        "        # move based on enhanced policy\n",
        "        # action = Pi.argmax() # greedy\n",
        "        action = np.random.choice(5, p=Pi)\n",
        "        action_history.append(action)\n",
        "        \n",
        "        # making the move in the grid world\n",
        "        grid_world, _, _ = make_move(grid_world, location_i, location_j, action)\n",
        "\n",
        "        if verbose==1:\n",
        "          print(action, end=\", \")\n",
        "        elif verbose==2:\n",
        "          clear_output(wait=True)\n",
        "          print(grid_world.map)\n",
        "\n",
        "\n",
        "    return state_history, action_history, reward, better_policy\n",
        "\n",
        "grid_world = Grid_world(map_num=10)\n",
        "print(grid_world.map)\n",
        "model = build_model(grid_world.shape)\n",
        "state_history, action_history, reward, better_policy = run_episode(grid_world, model, n_steps=8)"
      ],
      "metadata": {
        "id": "RjGcTM0ApSbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326427b4-e61c-4081-ac70-a15834c5b324"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  0  0]\n",
            " [-1 -1  0]\n",
            " [ 2  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_history, better_policy, reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE5w54AV7SWm",
        "outputId": "8582640d-4e21-4dcb-feea-c984f40761b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 0, 3, 3, 2, 2],\n",
              " [array([0.58783784, 0.11261261, 0.11261261, 0.11936937, 0.06756757]),\n",
              "  array([0.82692308, 0.04326923, 0.05608974, 0.04487179, 0.02884615]),\n",
              "  array([0.02797203, 0.01864802, 0.02797203, 0.91608392, 0.00932401]),\n",
              "  array([0.02059087, 0.0080573 , 0.01074306, 0.95434199, 0.00626679]),\n",
              "  array([0.0162086 , 0.00845666, 0.96124031, 0.0098661 , 0.00422833]),\n",
              "  array([0.0106383 , 0.00531915, 0.96335697, 0.01241135, 0.00827423])],\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The agent manages to solve multi-goal problems, but as the number of the goals increase the solution becomes less and less optimal.\n",
        " \n",
        "\n",
        "# TO INCREASE IMPROVMENT:\n",
        "# * introduce ranked rewards?\n",
        "\n",
        "# LTL: complex spesifications\n",
        "# * introduce LTL parser?\n",
        "\n",
        "# more general reward mechanism\n",
        "# tested with different scenarios\n",
        "# refactored some parts of the code (map maker)"
      ],
      "metadata": {
        "id": "1k_P10kX5Yvw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decayed_reward(size, init_rew, l=0.95):\n",
        "  \n",
        "  rew_seq = []\n",
        "\n",
        "  for i in range(size):\n",
        "    rew_seq.append(init_rew)\n",
        "    init_rew *= l\n",
        "  \n",
        "  return np.array(rew_seq)"
      ],
      "metadata": {
        "id": "URzY8wg9gUKa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_simulation(grid_world_shape, n_goals, ordered_goals=False, n_episodes=10, C=3, tow=1, n_steps=100, n_samples=300, N={}, W={}, Q={}, P={}, verbose=True):\n",
        "\n",
        "    grid_world_0 = Grid_world(map_num=grid_world_shape, n_goals=n_goals, ordered=ordered_goals)\n",
        "    if verbose: print(grid_world_0.map)\n",
        "    model = build_model(grid_world_0.shape)\n",
        "    for e in range(n_episodes):\n",
        "        \n",
        "        grid_world = grid_world_0.copy()\n",
        "        \n",
        "        state_history, action_history, reward, better_policy = run_episode(grid_world, model, n_steps=n_steps, n_samples=n_samples, tow=tow, C=C, N=N, W=W, Q=Q, P=P, verbose=2)\n",
        "\n",
        "        X = np.array(state_history).reshape(-1, grid_world.shape[0]*grid_world.shape[1])\n",
        "        y1 = np.array(better_policy)\n",
        "        # y2 = np.repeat(reward, len(better_policy))\n",
        "        y2 = decayed_reward(size=len(better_policy), init_rew=reward, l=1)[::-1]\n",
        "        model.fit(X, [y1, y2], epochs=50, verbose=0)\n",
        "\n",
        "        # model.fit(np.array(state_history), np.array(better_policy), epochs=30, verbose=0) # without value output\n",
        "\n",
        "        if verbose:\n",
        "          # print(N[hash_state(grid_world)])\n",
        "          # print(state_history)\n",
        "          root = hash_state(state_history[-1])\n",
        "          # print(\"N:\",N[root])\n",
        "          # print(\"Q:\",Q[root])\n",
        "          # print(\"U:\", C * P[root] * (np.sqrt(np.sum(N[root])))/(1+N[root]))\n",
        "          print(\"episode reward:\",reward, \",model value estimate of last step\", model(state_history[-1].reshape(1, -1))[1].numpy()[0][0])\n",
        "          print(\"Action history:\",\"(\",len(action_history),\")\", action_history)\n",
        "    #     if reward == 1: return True\n",
        "    # return False\n",
        "\n",
        "\n",
        "N, W, Q, P = {}, {}, {}, {}\n",
        "run_simulation(30, n_goals= 3, ordered_goals=True, n_episodes=5, C=1, tow=0.1, n_steps=30, n_samples=500, N=N, W=W, Q=Q, P=P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7xYmG0vpSdL",
        "outputId": "d6f2a23c-667f-449e-f34b-3214a1c61d49"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 -1  0 -1  0 -1  0  0  0  0]\n",
            " [ 0  0  0 -1  0 -1  0  0  0  0]\n",
            " [ 0  0  0 -1  0 -1  0  1  0  0]\n",
            " [ 0  0  0 -1  0 -1  0  0  0  0]\n",
            " [ 0  0  0  0  0 -1  0  0  0  0]\n",
            " [ 0  0  0  0  0 -1  0  0  0  0]\n",
            " [ 0 -1  0  0  0  0  0  0  0  0]\n",
            " [ 0 -1  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 -1  0  0  0  0  0  0]\n",
            " [ 0 -1  0  0  0  0  0  0  0  0]]\n",
            "episode reward: 1 ,model value estimate of last step 0.93364227\n",
            "Action history: ( 25 ) [3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 3, 2, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shapes = [(i,i) for i in range(5,38, 2)]\n",
        "results_1 = []\n",
        "print(\"1 goal\")\n",
        "for gw_shape in shapes:\n",
        "  print(gw_shape, end=\": \")\n",
        "  for _ in range(5):\n",
        "    N, W, Q, P = {}, {}, {}, {}\n",
        "    outcome = run_simulation(gw_shape, 1, n_episodes=3, C=1, tow=0.1, n_steps=gw_shape[0]*2+5, n_samples=500, N=N, W=W, Q=Q, P=P, verbose=False)\n",
        "    results_1.append(outcome)\n",
        "    print(outcome,end=\", \")\n",
        "  print()\n",
        "\n",
        "print(\"2 goals\")\n",
        "results_2 = []\n",
        "for gw_shape in shapes:\n",
        "  print(gw_shape, end=\": \")\n",
        "  for _ in range(5):\n",
        "    N, W, Q, P = {}, {}, {}, {}\n",
        "    outcome = run_simulation(gw_shape, 2, n_episodes=3, C=1, tow=0.1, n_steps=gw_shape[0]*2+5, n_samples=500, N=N, W=W, Q=Q, P=P, verbose=False)\n",
        "    results_2.append(outcome)\n",
        "    print(outcome,end=\", \")\n",
        "  print()\n",
        "\n",
        "print(\"3 goals\")\n",
        "results_3 = []\n",
        "for gw_shape in shapes:\n",
        "  print(gw_shape, end=\": \")\n",
        "  for _ in range(5):\n",
        "    N, W, Q, P = {}, {}, {}, {}\n",
        "    outcome = run_simulation(gw_shape, 3, n_episodes=3, C=1, tow=0.1, n_steps=gw_shape[0]*2+5, n_samples=500, N=N, W=W, Q=Q, P=P, verbose=False)\n",
        "    results_3.append(outcome)\n",
        "    print(outcome,end=\", \")\n",
        "  print()\n",
        "\n",
        "print(\"3 goals ordered\")\n",
        "results_3_1 = []\n",
        "for gw_shape in shapes:\n",
        "  print(gw_shape, end=\": \")\n",
        "  for _ in range(5):\n",
        "    N, W, Q, P = {}, {}, {}, {}\n",
        "    outcome = run_simulation(gw_shape, n_goals= 3, ordered_goals=True, n_episodes=3, C=1, tow=0.1, n_steps=gw_shape[0]*2+5, n_samples=500, N=N, W=W, Q=Q, P=P, verbose=False)\n",
        "    results_3_1.append(outcome)\n",
        "    print(outcome,end=\", \")\n",
        "  print()"
      ],
      "metadata": {
        "id": "pxGio4Lf4F5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(5,38,2), np.reshape(results_1, (-1, 5)).mean(1))\n",
        "plt.title(\"success rate based on levels of complexity (1 goal)\")\n",
        "plt.xlabel(\"dim of grid_wrold\")\n",
        "plt.ylabel(\"success rate\")\n",
        "plt.figure()\n",
        "\n",
        "plt.bar(range(5,38,2), np.reshape(results_2, (-1, 5)).mean(1))\n",
        "plt.title(\"success rate based on levels of complexity (2 goals)\")\n",
        "plt.xlabel(\"dim of grid_wrold\")\n",
        "plt.ylabel(\"success rate\")"
      ],
      "metadata": {
        "id": "xlIbjGwDYD4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(5,38,2), np.reshape(results_3, (-1, 5)).mean(1))\n",
        "plt.title(\"success rate based on levels of complexity (3 goals)\")\n",
        "plt.xlabel(\"dim of grid_wrold\")\n",
        "plt.ylabel(\"success rate\");"
      ],
      "metadata": {
        "id": "FNujD7wNnP7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(5,38,2), np.reshape(results_3_2, (-1, 5)).mean(1))\n",
        "plt.title(\"success rate based on levels of complexity (3 ordered goals)\")\n",
        "plt.xlabel(\"dim of grid_wrold\")\n",
        "plt.ylabel(\"success rate\");"
      ],
      "metadata": {
        "id": "OtKilKVxmQGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.reshape(results, (-1, 10)).mean(1)\n",
        "# plt.plot(results)\n",
        "fin_res = np.ones(30)\n",
        "fin_res[5:25] = res.mean(1)\n",
        "fin_res[25:] = np.reshape(results, (-1, 10)).mean(1)\n",
        "fin_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xyTx_GCj82H",
        "outputId": "113247c9-36d2-4f69-d05b-3cc679f7c469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1. , 1. , 1. , 1. , 1. , 1. , 1. , 0.9, 1. , 1. , 0.9, 1. , 1. ,\n",
              "       1. , 1. , 0.8, 0.9, 0.7, 0.6, 0.9, 0.7, 1. , 0.5, 0.7, 0.7, 1. ,\n",
              "       1. , 1. , 1. , 1. ])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# res = np.reshape(results, (20, 10))\n",
        "res.mean(1)\n",
        "plt.bar(range(5,25), res.mean(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ovghDaJciyhc",
        "outputId": "43d77cd4-36cd-425d-ed9f-99a615eb77bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_world = reset_grid_world(21)\n",
        "grid_world, hash_state(grid_world)"
      ],
      "metadata": {
        "id": "iS0XOCEJC4sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in N:\n",
        "  print(i, N[i])"
      ],
      "metadata": {
        "id": "Es7zxraVT0Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array([0,0,0,0,0])\n",
        "model(t.reshape(1, -1))[0][0].numpy().argmax()"
      ],
      "metadata": {
        "id": "8E_2jlHesbGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_world= reset_grid_world()\n",
        "state_history, action_history, reward, possible_policy = run_episode(grid_world.copy(), model, eps=0.1)"
      ],
      "metadata": {
        "id": "sXb0afjjpSf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_movement(states):\n",
        "  grid_world = reset_grid_world()\n",
        "  goal_location = get_locations(grid_world, 2)\n",
        "  obstacle_locations = get_locations(grid_world, -1)\n",
        "  for state in states:\n",
        "    i, j = int(state[0]//5), int(state[0]%5)\n",
        "    grid_world[i,j] = 1\n",
        "    print(grid_world)\n",
        "    grid_world[i][j] = 0\n",
        "    print()\n",
        "\n",
        "print(model(np.reshape([0, -1, -1, -1, 0], (1, -1)))[0].numpy(), model(np.reshape([0, -1, -1, -1, 0], (1, -1)))[0].numpy().argmax())"
      ],
      "metadata": {
        "id": "YMGbeUdipSi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_movement(state_history)"
      ],
      "metadata": {
        "id": "oEj1GL9Q06fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PROBLEMS:\n",
        "\n",
        "# infinite loops\n",
        "# too long tragectories, agent can't find the way\n",
        "# tree search helps it NAVIGATE, but it usually gets stuck\n",
        "\n",
        "# effect of positive/negative rewards on the path taken\n",
        "    # use value functions?  \n",
        "    # intermediate rewards?\n",
        "    # deep MCTS?\n",
        "\n",
        "# * turn this into a simple baseline to try out different methods (ranked rewards,...)"
      ],
      "metadata": {
        "id": "6Nl-a2OM1KLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 goal\n",
        "results_1=[\n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, False, True, True, True, \n",
        "False, True, True, True, True, \n",
        "False, True, True, True, True, \n",
        "False, True, True, True, True, \n",
        "False, True, True, False, True, \n",
        "False, True, True, True, True, \n",
        "True, False, True, True, False, \n",
        "True, False, True, True, False, \n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, False, False, False, True, \n",
        "True, True, True, False, True, \n",
        "False, True, True, False, False]\n",
        "\n",
        "# 2 goals\n",
        "results_2=[\n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, False, True, True, False, \n",
        "True, True, False, False, True, \n",
        "True, True, True, True, True, \n",
        "False, True, True, True, False, \n",
        "True, False, True, False, True, \n",
        "True, True, True, True, True, \n",
        "False, True, False, True, False, \n",
        "False, False, True, False, True, \n",
        "False, False, False, True, True, \n",
        "False, False, True, False, False, \n",
        "True, True, False, True, False, \n",
        "False, False, False, False, True,\n",
        "False, False, False, False, False]\n",
        "\n",
        "# 3 goals\n",
        "results_3=[\n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, True, True, True, True, \n",
        "True, True, True, False, True, \n",
        "True, False, True, True, True, \n",
        "True, True, False, False, True, \n",
        "True, True, True, True, True, \n",
        "False, True, True, True, False, \n",
        "True, False, False, True, True, \n",
        "True, False, False, False, True, \n",
        "True, True, True, True, False, \n",
        "False, False, True, False, True, \n",
        "False, False, False, True, True, \n",
        "False, True, False, False, False, \n",
        "False, False, True, True, False, \n",
        "False, False, False, True, False,\n",
        "False, False, False, False, True]\n",
        "\n",
        "# ordered goals \n",
        "results_3_2=[\n",
        "True, False, False, True, True, \n",
        "True, True, True, True, True, \n",
        "True, False, False, True, True, \n",
        "True, True, False, False, True, \n",
        "True, False, True, True, True, \n",
        "False, True, False, False, True, \n",
        "False, False, False, True, True, \n",
        "False, True, True, True, False, \n",
        "True, False, False, False, True, \n",
        "False, False, False, False, True, \n",
        "False, True, False, True, False, \n",
        "False, False, False, True, False, \n",
        "True, False, False, False, False, \n",
        "False, False, False, False, False, \n",
        "True, False, False, False, False, \n",
        "False, False, True, False, False,\n",
        "False, False, False, False, False]"
      ],
      "metadata": {
        "id": "5zukkkTytFdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78b5LyLohd-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eX7FFYtKiEPA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}